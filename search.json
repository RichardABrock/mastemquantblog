[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mastemquantblog",
    "section": "",
    "text": "Trends in PISA science scores\n\n\n\n\n\n\n\n\n\n\n\n\nKaty Bray\n\n\n\n\n\n\n  \n\n\n\n\nDifferences in PISA mathematics scores in the US and UK\n\n\n\n\n\n\n\n\n\n\n\n\nManasi Rajan\n\n\n\n\n\n\n  \n\n\n\n\nGender differences in PISA\n\n\n\n\n\n\n\n\n\n\n\n\nKaty Bray\n\n\n\n\n\n\n  \n\n\n\n\nWho’s Better Educated, Mum or Dad?\n\n\n\n\n\n\n\n\n\n\n\n\nOwen James-Gray\n\n\n\n\n\n\n  \n\n\n\n\nWorking Time graph\n\n\n\n\n\n\n\n\n\n\n\n\nOwen James-Gray\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To STEM MA Quantitative methods in Educational Research Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nRichard Brock and Peter Kemp\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To STEM MA Quantitative methods in Educational Research Blog",
    "section": "",
    "text": "We will use this blog to display student work from the MA STEM Quantitative methods in Educational Research module at King’s College London. You can see the course book here MASTEMR\n\n# Create a dataframe of country latitude and longitude data\nworld_data &lt;- map_data(map=\"world\")\n\n# Create a dataframe of mean PISA science scores, and rename CNT to region\n# for the leftjoin mergining of dataframes\nWorldSci &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(meanSci = mean(PV1SCIE)) %&gt;%\n  rename(region = CNT)\n\nlevels(WorldSci$region)[levels(WorldSci$region)==\"United Kingdom\"] &lt;- \"UK\"\nlevels(WorldSci$region)[levels(WorldSci$region)==\"United States\"] &lt;- \"USA\"\n\nViet&lt;-PISA_2022%&gt;%\n  select(PV1SCIE, CNT)%&gt;%\n  filter(CNT==\"Vietnam\")\n  \n# Add the country latitude and longitude data to the PISA scores\nWorldSci&lt;-left_join(world_data, WorldSci, by=\"region\")\n# Use geom_map to plot the basic world map (fill is white, line colour is black)\n# Use geom_polygon to plot the PISA data\n# Add a colour scale\n\nLabels&lt;-WorldSci%&gt;%\n  group_by(region)%&gt;%\n  summarise(meanSci=mean(meanSci), lat=mean(lat), long=mean(long))%&gt;%\n  na.omit()\n\n\n\nggplot(data = WorldSci, aes(x=long, y=lat, group=group)) +\n  geom_map(data=world_data, map=world_data, aes(map_id=region), fill=\"white\", colour=\"black\")+\n  geom_polygon(aes(fill=meanSci)) +\n  scale_fill_viridis_c(option = \"viridis\")+\n  geom_text_repel(data=Labels, inherit.aes = F, aes(x=long, y=lat,label=region),\n                  size=3)+\n  ggtitle(\"Mean PISA 2022 scoures by country\")+\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The blog for the KCL MA STEM Quantitative Methods in Educational Research Module. This blog will display student work produced in R."
  },
  {
    "objectID": "posts/test post/MASTEMquant.html",
    "href": "posts/test post/MASTEMquant.html",
    "title": "MASTEMQuant",
    "section": "",
    "text": "This is a page to show student work from the MA STEM Quantitative Methods in Educational Research Module"
  },
  {
    "objectID": "posts/test post/MASTEMquant.html#ma-stem-education-quantitative-methods-in-educational-research---student-projects",
    "href": "posts/test post/MASTEMquant.html#ma-stem-education-quantitative-methods-in-educational-research---student-projects",
    "title": "MASTEMQuant",
    "section": "",
    "text": "This is a page to show student work from the MA STEM Quantitative Methods in Educational Research Module"
  },
  {
    "objectID": "posts/test post/MASTEMquant.html#example-code",
    "href": "posts/test post/MASTEMquant.html#example-code",
    "title": "MASTEMQuant",
    "section": "Example code",
    "text": "Example code\n\n# Create a UK subset\nPISAUK&lt;-PISA_2018%&gt;%\n  filter(CNT==\"United Kingdom\")%&gt;%\n  select(PV1SCIE, PV1MATH)\n# Plot scores, but add them to bins to reduce over ploting\n# Set a colour scale to show number in bins\nggplot(PISAUK, aes(x=PV1MATH, y=PV1SCIE))+\n  stat_bin2d(bins = 90) +\n  scale_fill_gradient(low = \"lightblue\", high = \"red\", limits = c(0, 80))+\n  ggtitle(\"UK PISA Science and Mathematics scores\")+\n  labs(x=\"Mathematics score\", y=\"Science Score\")"
  },
  {
    "objectID": "posts/P8Analysis/P8Analysis.html",
    "href": "posts/P8Analysis/P8Analysis.html",
    "title": "P8Data20222023",
    "section": "",
    "text": "library(BayesFactor)\n\nLoading required package: coda\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n************\nWelcome to BayesFactor 0.9.12-4.5. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).\n\nType BFManual() to open the manual.\n************\n\nsubset&lt;-dfe2023%&gt;%\n  select(P8MEA,PTFSM6CLA1A, PTEALGRP2, PSENE4)\nsubset$P8MEA&lt;-as.numeric(subset$P8MEA)\n\nsubset$PTFSM6CLA1A&lt;-parse_number(subset$PTFSM6CLA1A)\n\nWarning: 1818 parsing failures.\nrow col expected actual\n  1  -- a number     NP\n  2  -- a number     NP\n  3  -- a number     NP\n  7  -- a number     NP\n  8  -- a number     NP\n... ... ........ ......\nSee problems(...) for more details.\n\nsubset$PTEALGRP2&lt;-parse_number(subset$PTEALGRP2)\n\nWarning: 1833 parsing failures.\nrow col expected actual\n  1  -- a number     NP\n  2  -- a number     NP\n  3  -- a number     NP\n  7  -- a number     NP\n  8  -- a number     NP\n... ... ........ ......\nSee problems(...) for more details.\n\nsubset$PSENE4&lt;-parse_number(subset$PSENE4)\n\nWarning: 1 parsing failure.\n row col expected actual\n7355  -- a number   SUPP\n\nsubset&lt;-subset%&gt;%\n  na.omit()\nmodels&lt;-regressionBF(P8MEA ~ ., data = subset)\n\nWarning: data coerced from tibble to data frame\n\noutput&lt;-as.data.frame(models@bayesFactor)\n\nggplot(output, aes(x=reorder(rownames(output), - bf), y=bf, fill=rownames(output)))+\n  geom_col() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "posts/P8Analysis/P8Analysis.html#p8-analysis",
    "href": "posts/P8Analysis/P8Analysis.html#p8-analysis",
    "title": "P8Data20222023",
    "section": "",
    "text": "library(BayesFactor)\n\nLoading required package: coda\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n************\nWelcome to BayesFactor 0.9.12-4.5. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).\n\nType BFManual() to open the manual.\n************\n\nsubset&lt;-dfe2023%&gt;%\n  select(P8MEA,PTFSM6CLA1A, PTEALGRP2, PSENE4)\nsubset$P8MEA&lt;-as.numeric(subset$P8MEA)\n\nsubset$PTFSM6CLA1A&lt;-parse_number(subset$PTFSM6CLA1A)\n\nWarning: 1818 parsing failures.\nrow col expected actual\n  1  -- a number     NP\n  2  -- a number     NP\n  3  -- a number     NP\n  7  -- a number     NP\n  8  -- a number     NP\n... ... ........ ......\nSee problems(...) for more details.\n\nsubset$PTEALGRP2&lt;-parse_number(subset$PTEALGRP2)\n\nWarning: 1833 parsing failures.\nrow col expected actual\n  1  -- a number     NP\n  2  -- a number     NP\n  3  -- a number     NP\n  7  -- a number     NP\n  8  -- a number     NP\n... ... ........ ......\nSee problems(...) for more details.\n\nsubset$PSENE4&lt;-parse_number(subset$PSENE4)\n\nWarning: 1 parsing failure.\n row col expected actual\n7355  -- a number   SUPP\n\nsubset&lt;-subset%&gt;%\n  na.omit()\nmodels&lt;-regressionBF(P8MEA ~ ., data = subset)\n\nWarning: data coerced from tibble to data frame\n\noutput&lt;-as.data.frame(models@bayesFactor)\n\nggplot(output, aes(x=reorder(rownames(output), - bf), y=bf, fill=rownames(output)))+\n  geom_col() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "posts/P8Analysis/P8Analysis.html#grouped-scatter-plot-with-marginal-density-plots",
    "href": "posts/P8Analysis/P8Analysis.html#grouped-scatter-plot-with-marginal-density-plots",
    "title": "P8Data20222023",
    "section": "Grouped Scatter plot with marginal density plots",
    "text": "Grouped Scatter plot with marginal density plots\n\nlibrary(ggpubr)\n\n# Grouped Scatter plot with marginal density plots\n\nplotdata&lt;-dfe2023%&gt;%\n  filter(ICLOSE==0)%&gt;%\n  filter(P8MEA!=\"NP\")%&gt;%\n  filter(P8MEA!=\"NE\")%&gt;%\n  filter(P8MEA!=\"SUPP\")%&gt;%\n  select(P8MEA, PTFSM6CLA1A, ADMPOL,SCHNAME)%&gt;%\n  na.omit()%&gt;%\n  mutate(label=ifelse(P8MEA&gt;1.3,SCHNAME,\"\"))%&gt;%\n  mutate(ADMPOL=ifelse(ADMPOL==\"NR\",\"Not recorded\",\n                       ifelse(ADMPOL==\"SEL\",\"Selective\", \n                              ifelse(ADMPOL==\"NSE\",\"Not selective\", NA))))\nplotdata$P8MEA&lt;-as.numeric(plotdata$P8MEA)\n\nplotdata$PTFSM6CLA1A&lt;-parse_number(plotdata$PTFSM6CLA1A)\n\nggscatterhist(data=plotdata, y=\"P8MEA\", x=\"PTFSM6CLA1A\",\n              color =\"ADMPOL\", size = 0.5, alpha = 0.4,\n              margin.params = list(fill = \"ADMPOL\", color = \"black\", size = 0.2),\n              ggtheme = theme_bw())"
  },
  {
    "objectID": "posts/P8Analysis/P8Analysis.html#section",
    "href": "posts/P8Analysis/P8Analysis.html#section",
    "title": "P8Data20222023",
    "section": "",
    "text": "P8 Best model\n\nlibrary(BayesFactor)\n\nsubset&lt;-dfe2023%&gt;%\n  select(P8MEA,PTFSM6CLA1A, PTEALGRP2, PSENE4)\nsubset$P8MEA&lt;-as.numeric(subset$P8MEA)\n\nsubset$PTFSM6CLA1A&lt;-parse_number(subset$PTFSM6CLA1A)\n\nWarning: 1818 parsing failures.\nrow col expected actual\n  1  -- a number     NP\n  2  -- a number     NP\n  3  -- a number     NP\n  7  -- a number     NP\n  8  -- a number     NP\n... ... ........ ......\nSee problems(...) for more details.\n\nsubset$PTEALGRP2&lt;-parse_number(subset$PTEALGRP2)\n\nWarning: 1833 parsing failures.\nrow col expected actual\n  1  -- a number     NP\n  2  -- a number     NP\n  3  -- a number     NP\n  7  -- a number     NP\n  8  -- a number     NP\n... ... ........ ......\nSee problems(...) for more details.\n\nsubset$PSENE4&lt;-parse_number(subset$PSENE4)\n\nWarning: 1 parsing failure.\n row col expected actual\n7355  -- a number   SUPP\n\nsubset&lt;-subset%&gt;%\n  na.omit()\nmodels&lt;-regressionBF(P8MEA ~ ., data = subset)\n\nWarning: data coerced from tibble to data frame\n\noutput&lt;-as.data.frame(models@bayesFactor)\n\nggplot(output, aes(x=reorder(rownames(output), - bf), y=bf, fill=rownames(output)))+\n  geom_col() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "posts/Post 1/Post1.html",
    "href": "posts/Post 1/Post1.html",
    "title": "PISA 2022 science and mathematics scores",
    "section": "",
    "text": "Correlation between mathematics and science scores in PISA 2022 data"
  },
  {
    "objectID": "posts/Post 1/Post1.html#patterns-of-science-and-mathematics-achievement",
    "href": "posts/Post 1/Post1.html#patterns-of-science-and-mathematics-achievement",
    "title": "PISA 2022 science and mathematics scores",
    "section": "",
    "text": "Correlation between mathematics and science scores in PISA 2022 data"
  },
  {
    "objectID": "posts/Working Graph/Working Graph.html",
    "href": "posts/Working Graph/Working Graph.html",
    "title": "Working Time graph",
    "section": "",
    "text": "Looking through the questions asked on the PISA_2022 dataset I saw that the number of times a student had worked a job during the week was included as WORKPAY. I was interested to see if this had an effect on their scores in the tested domains of reading, maths and science. I had a couple of hypothesis to check that work in opposite directions.\n\n\n\nWorking in free time during non-school hours displays a strong work ethic and hence that same work ethic could be applied to school work too.\n\n\n\nWorking in their free time has an opportunity cost, every hour spent working is an hour that could have been spent studying, resulting in a negative impact on PISA score.\n\n\n\nUsing R I took the PISA 2022 dataset, averaged the three scores (reading PV1READ, maths PV1MATH and science PV1SCIE) of each pupil to get a total score for each pupil (SCORE_AVG).\nI realised that certain countries with different levels of economic development and different cultures surrounding children working may also have different PISA scores so I came up with a modified pupil score relative to the scores of their own country, this score represents the number of standard deviations a student is away from the average score of their own country (STU_REL_SCORE) so for example a value of -0.55 would mean that student had an average score in the three domains that was 0.55 standard deviations below the country average score. This was then compared against the number of times a student had worked during the week (WORKPAY).\nHere is the code:\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[PISA_student_2022_subset.parquet]\")\n\navg_score &lt;- PISA_2022 %&gt;% \n  select(CNT, PV1MATH, PV1READ, PV1SCIE, WORKPAY) %&gt;% \n  mutate(SCORE_AVG = ((PV1MATH + PV1READ + PV1SCIE)/3)) %&gt;% \n  group_by(CNT) %&gt;% \n  mutate(CNT_AVG_SCORE = mean(SCORE_AVG)) %&gt;%\n  mutate(CNT_SD_SCORE = sd(SCORE_AVG)) %&gt;% \n  ungroup() %&gt;% \n  mutate(STU_REL_SCORE = ((SCORE_AVG-CNT_AVG_SCORE)/CNT_SD_SCORE)) %&gt;% \n  select(CNT, SCORE_AVG, CNT_AVG_SCORE, CNT_SD_SCORE, STU_REL_SCORE, WORKPAY) %&gt;%\n  filter(!is.na(WORKPAY))\n\nWhen plotted this results in the following graph:\n\n# Define a custom function to map original levels to shorter labels\nmap_workpay_labels &lt;- function(original_label) {\n  # Define mapping for each level\n  level_mapping &lt;- c(\n    \"No work for pay\" = \"zero\",\n    \"1 time of working for pay per week\" = \"one\",\n    \"2 times of working for pay per week\" = \"two\",\n    \"3 times of working for pay per week\" = \"three\",\n    \"4 times of working for pay per week\" = \"four\",\n    \"5 times of working for pay per week\" = \"five\",\n    \"6 times of working for pay per week\" = \"six\",\n    \"7 times of working for pay per week\" = \"seven\",\n    \"8 times of working for pay per week\" = \"eight\",\n    \"9 times of working for pay per week\" = \"nine\",\n    \"10 or more times of working for pay per week\" = \"more than ten\"\n  )\n  \n  # Use the level_mapping to map the original_label to the shorter label\n  return(level_mapping[original_label])\n}\n\n# Apply the custom function to the \"WORKPAY\" column\navg_score$WORKPAY &lt;- sapply(avg_score$WORKPAY, map_workpay_labels)\n\n# Convert \"WORKPAY\" to a factor with desired order of levels\navg_score$WORKPAY &lt;- factor(avg_score$WORKPAY, levels = c(\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"more than ten\"))\n\nggplot(data = avg_score,\n       aes(x=WORKPAY, y=STU_REL_SCORE)) +\n  geom_violin(fill=\"lightblue\")+\n  ggtitle(\"How working affects student scores across the world\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  xlab(\"Number of times worked per week\") +\n  ylab(\"Student average score normalised relative to own country\") +\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\nIn which there does seem to be a negative correlation between number of times a student works and their relative score.\nThis is made clearer if we remove the violin distribution plots and just look at the averages. The times worked per week as contained within the PISA dataset is a categoric variable so in order to do a linear plot it needs to be made into a numeric variable first so the little bit of code below does that before then plotting a line graph.\n\navg_score &lt;- PISA_2022 %&gt;% \n  select(CNT, PV1MATH, PV1READ, PV1SCIE, WORKPAY, ESCS) %&gt;% \n  mutate(SCORE_AVG = ((PV1MATH + PV1READ + PV1SCIE)/3)) %&gt;% \n  group_by(CNT) %&gt;% \n  mutate(CNT_AVG_SCORE = mean(SCORE_AVG)) %&gt;%\n  mutate(CNT_SD_SCORE = sd(SCORE_AVG)) %&gt;% \n  ungroup() %&gt;% \n  mutate(STU_REL_SCORE = ((SCORE_AVG-CNT_AVG_SCORE)/CNT_SD_SCORE)) %&gt;% \n  select(CNT, SCORE_AVG, CNT_AVG_SCORE, CNT_SD_SCORE, STU_REL_SCORE, WORKPAY,ESCS) %&gt;%\n  mutate(WORKPAY_numeric = \n           case_when(WORKPAY == \"No work for pay\" ~ 0,\n                     WORKPAY == \"1 time of working for pay per week\" ~ 1,\n                     WORKPAY == \"2 times of working for pay per week\" ~ 2,\n                     WORKPAY == \"3 times of working for pay per week\" ~ 3,\n                     WORKPAY == \"4 times of working for pay per week\" ~ 4,\n                     WORKPAY == \"5 times of working for pay per week\" ~ 5,\n                     WORKPAY == \"6 times of working for pay per week\" ~ 6,\n                     WORKPAY == \"7 times of working for pay per week\" ~ 7,\n                     WORKPAY == \"8 times of working for pay per week\" ~ 8,\n                     WORKPAY == \"9 times of working for pay per week\" ~ 9,\n                     WORKPAY == \"10 or more times of working for pay per week\" ~ NA,\n                     .default = NA)) %&gt;%\n  filter(!is.na(WORKPAY_numeric))\n\nggplot(data = avg_score,\n       aes(x=WORKPAY_numeric, y=STU_REL_SCORE)) +\n  geom_smooth(method = 'lm')+\n  scale_x_continuous(breaks = 0:10)+\n  ggtitle(\"How working affects student scores across the world\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  xlab(\"Number of times worked per week\") +\n  ylab(\"Student average score normalised relative to own country\") +\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\nWhich does show more clearly a negative correlation between times worked per week when times is less than 5. The correlation gets a little more noisy after that. I speculate this is because working more than 5 times per week would mean working more than every weekday, which might mean students answering the questionnaire with larger numbers may be defining a “working” period differently than those answering with smaller values or perhaps have misread the question making the data noisier for values over 5.\nOne thing in discussion with Peter and Richard I realised was that this model while it takes account of differences in economic status by country, it does not take into account differences in socioeconomic status between students. It is completely plausible that even within a country poorer students might be having to work more than richer ones, and it is fairly established that students with lower socioeconomic status get lower scores on PISA tests (Tessier 2018). This might mean that all we are seeing in this graph is that effect, rather than any effect from working in a job. To remedy this we can adapt our model to control for socioeconomic status (ESCS).\n\n\n\nFirst of all let’s see if there is a relationship between a student working in a job and their ESCS.\n\nescs_vs_work &lt;- PISA_2022 %&gt;% \n  select(WORKPAY, ESCS) %&gt;% \n  mutate(WORKPAY_numeric = \n           case_when(WORKPAY == \"No work for pay\" ~ 0,\n                     WORKPAY == \"1 time of working for pay per week\" ~ 1,\n                     WORKPAY == \"2 times of working for pay per week\" ~ 2,\n                     WORKPAY == \"3 times of working for pay per week\" ~ 3,\n                     WORKPAY == \"4 times of working for pay per week\" ~ 4,\n                     WORKPAY == \"5 times of working for pay per week\" ~ 5,\n                     WORKPAY == \"6 times of working for pay per week\" ~ 6,\n                     WORKPAY == \"7 times of working for pay per week\" ~ 7,\n                     WORKPAY == \"8 times of working for pay per week\" ~ 8,\n                     WORKPAY == \"9 times of working for pay per week\" ~ 9,\n                     WORKPAY == \"10 or more times of working for pay per week\" ~ NA,\n                     .default = NA)) %&gt;%\n  filter(!is.na(WORKPAY_numeric)) %&gt;% \n  filter(!is.na(ESCS))\n\nggplot(data = escs_vs_work,\n       aes(x=WORKPAY_numeric, y=ESCS)) +\n  geom_smooth(method = 'lm')+\n  scale_x_continuous(breaks = 0:10)+\n  ggtitle(\"Do low socioeconomic status students work more times a week?\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  xlab(\"Number of times worked per week\") +\n  ylab(\"Student socioeconomic status\") +\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\nClearly there is a negative correlation, students who work more times per week are also of lower socioeconomic status. An interesting aside that I cannot explain is that odd working times per week lower than 5 have higher ESCS and even working times above 5 have higher ESCS. I think this may be because the WORKPAY category is a composite category made from two questions “How many times in the last week did you work for pay after school?” and “How many times in the last week did you work for pay before school?” This is pure speculation but perhaps there is some difference in ESCS between students who work before and after school, and the way the two questions are being aggregated is showing that up. I could possibly use the full PISA data set to look at the responses to those individual questions but that would perhaps be a distraction from the current investigation.\nLet’s compare the correlations between WORKPAY and ESCS to see how much they are correlated.\n\ncor.test(escs_vs_work$WORKPAY_numeric, escs_vs_work$ESCS, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  escs_vs_work$WORKPAY_numeric and escs_vs_work$ESCS\nt = -50.101, df = 529231, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07138745 -0.06602455\nsample estimates:\n        cor \n-0.06870649 \n\n\nWhile the relationship is incredibly significant (p &lt; 2.2e-16), there is only a small negative correlation (-0.0687). Let’s compare this with the correlation between WORKPAY and STU_REL_SCORE.\n\ncor.test(avg_score$WORKPAY_numeric, avg_score$STU_REL_SCORE, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  avg_score$WORKPAY_numeric and avg_score$STU_REL_SCORE\nt = -163.69, df = 537551, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2204415 -0.2153489\nsample estimates:\n       cor \n-0.2178967 \n\n\nAgain an incredibly significant result (p &lt; 2.2e-16), but this time the correlation is more than 3 times greater (-0.218). We are not done as we should do a final correlation test between ESCS and STU_REL_SCORE to be able to see how much of a difference the two variables have compared to each other.\n\ncor.test(avg_score$ESCS, avg_score$STU_REL_SCORE, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  avg_score$ESCS and avg_score$STU_REL_SCORE\nt = 237.46, df = 529231, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3078603 0.3127298\nsample estimates:\n      cor \n0.3102971 \n\n\nOnce again incredibly significant (p &lt; 2.2e-16), the correlation is similar to the WORKPAY correlation but about 50% higher (0.310) and positive instead of negative. Given the negligible correlation between WORKPAY and ESCS and the weak to moderate correlations between WORKPAY, ESCS and STU_REL_SCORE we can be fairly confident that WORKPAY does have an effect on STU_REL_SCORE. However to find out how much of a effect WORKPAY is having we can do a multiple linear regression controlling for ESCS.\n\nlibrary(easystats)\nmodel &lt;- lm(STU_REL_SCORE ~ WORKPAY_numeric + ESCS,\n            data=avg_score)\nsummary(model)\n\n\nCall:\nlm(formula = STU_REL_SCORE ~ WORKPAY_numeric + ESCS, data = avg_score)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8889 -0.6290 -0.0027  0.6252  4.3940 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.2518582  0.0014245   176.8   &lt;2e-16 ***\nWORKPAY_numeric -0.1003225  0.0006479  -154.9   &lt;2e-16 ***\nESCS             0.2622097  0.0011323   231.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9163 on 529230 degrees of freedom\n  (8320 observations deleted due to missingness)\nMultiple R-squared:  0.1355,    Adjusted R-squared:  0.1355 \nF-statistic: 4.146e+04 on 2 and 529230 DF,  p-value: &lt; 2.2e-16\n\nreport(model)\n\nWe fitted a linear model (estimated using OLS) to predict STU_REL_SCORE with\nWORKPAY_numeric and ESCS (formula: STU_REL_SCORE ~ WORKPAY_numeric + ESCS). The\nmodel explains a statistically significant and moderate proportion of variance\n(R2 = 0.14, F(2, 529230) = 41459.59, p &lt; .001, adj. R2 = 0.14). The model's\nintercept, corresponding to WORKPAY_numeric = 0 and ESCS = 0, is at 0.25 (95%\nCI [0.25, 0.25], t(529230) = 176.81, p &lt; .001). Within this model:\n\n  - The effect of WORKPAY numeric is statistically significant and negative (beta\n= -0.10, 95% CI [-0.10, -0.10], t(529230) = -154.85, p &lt; .001; Std. beta =\n-0.20, 95% CI [-0.20, -0.20])\n  - The effect of ESCS is statistically significant and positive (beta = 0.26,\n95% CI [0.26, 0.26], t(529230) = 231.56, p &lt; .001; Std. beta = 0.30, 95% CI\n[0.29, 0.30])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nSo, even when taking into account the household socioeconomic status there is a small but significant effect of a student having to work during the weekdays. This model explains 14% of the variance in STU_REL_SCORE. Combined with the discoveries above that WORKPAY has little correlation with ESCS we can be fairly confident in it’s effect on student outcomes.\nTo summarise; maybe if I hadn’t worked at Homebase when I was 17 years old I’d have got an A in my chemistry A-level instead of a B."
  },
  {
    "objectID": "posts/Working Graph/Working Graph.html#does-working-a-job-impact-student-performance",
    "href": "posts/Working Graph/Working Graph.html#does-working-a-job-impact-student-performance",
    "title": "Working Time graph",
    "section": "",
    "text": "Looking through the questions asked on the PISA_2022 dataset I saw that the number of times a student had worked a job during the week was included as WORKPAY. I was interested to see if this had an effect on their scores in the tested domains of reading, maths and science. I had a couple of hypothesis to check that work in opposite directions.\n\n\n\nWorking in free time during non-school hours displays a strong work ethic and hence that same work ethic could be applied to school work too.\n\n\n\nWorking in their free time has an opportunity cost, every hour spent working is an hour that could have been spent studying, resulting in a negative impact on PISA score.\n\n\n\nUsing R I took the PISA 2022 dataset, averaged the three scores (reading PV1READ, maths PV1MATH and science PV1SCIE) of each pupil to get a total score for each pupil (SCORE_AVG).\nI realised that certain countries with different levels of economic development and different cultures surrounding children working may also have different PISA scores so I came up with a modified pupil score relative to the scores of their own country, this score represents the number of standard deviations a student is away from the average score of their own country (STU_REL_SCORE) so for example a value of -0.55 would mean that student had an average score in the three domains that was 0.55 standard deviations below the country average score. This was then compared against the number of times a student had worked during the week (WORKPAY).\nHere is the code:\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[PISA_student_2022_subset.parquet]\")\n\navg_score &lt;- PISA_2022 %&gt;% \n  select(CNT, PV1MATH, PV1READ, PV1SCIE, WORKPAY) %&gt;% \n  mutate(SCORE_AVG = ((PV1MATH + PV1READ + PV1SCIE)/3)) %&gt;% \n  group_by(CNT) %&gt;% \n  mutate(CNT_AVG_SCORE = mean(SCORE_AVG)) %&gt;%\n  mutate(CNT_SD_SCORE = sd(SCORE_AVG)) %&gt;% \n  ungroup() %&gt;% \n  mutate(STU_REL_SCORE = ((SCORE_AVG-CNT_AVG_SCORE)/CNT_SD_SCORE)) %&gt;% \n  select(CNT, SCORE_AVG, CNT_AVG_SCORE, CNT_SD_SCORE, STU_REL_SCORE, WORKPAY) %&gt;%\n  filter(!is.na(WORKPAY))\n\nWhen plotted this results in the following graph:\n\n# Define a custom function to map original levels to shorter labels\nmap_workpay_labels &lt;- function(original_label) {\n  # Define mapping for each level\n  level_mapping &lt;- c(\n    \"No work for pay\" = \"zero\",\n    \"1 time of working for pay per week\" = \"one\",\n    \"2 times of working for pay per week\" = \"two\",\n    \"3 times of working for pay per week\" = \"three\",\n    \"4 times of working for pay per week\" = \"four\",\n    \"5 times of working for pay per week\" = \"five\",\n    \"6 times of working for pay per week\" = \"six\",\n    \"7 times of working for pay per week\" = \"seven\",\n    \"8 times of working for pay per week\" = \"eight\",\n    \"9 times of working for pay per week\" = \"nine\",\n    \"10 or more times of working for pay per week\" = \"more than ten\"\n  )\n  \n  # Use the level_mapping to map the original_label to the shorter label\n  return(level_mapping[original_label])\n}\n\n# Apply the custom function to the \"WORKPAY\" column\navg_score$WORKPAY &lt;- sapply(avg_score$WORKPAY, map_workpay_labels)\n\n# Convert \"WORKPAY\" to a factor with desired order of levels\navg_score$WORKPAY &lt;- factor(avg_score$WORKPAY, levels = c(\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"more than ten\"))\n\nggplot(data = avg_score,\n       aes(x=WORKPAY, y=STU_REL_SCORE)) +\n  geom_violin(fill=\"lightblue\")+\n  ggtitle(\"How working affects student scores across the world\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  xlab(\"Number of times worked per week\") +\n  ylab(\"Student average score normalised relative to own country\") +\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\nIn which there does seem to be a negative correlation between number of times a student works and their relative score.\nThis is made clearer if we remove the violin distribution plots and just look at the averages. The times worked per week as contained within the PISA dataset is a categoric variable so in order to do a linear plot it needs to be made into a numeric variable first so the little bit of code below does that before then plotting a line graph.\n\navg_score &lt;- PISA_2022 %&gt;% \n  select(CNT, PV1MATH, PV1READ, PV1SCIE, WORKPAY, ESCS) %&gt;% \n  mutate(SCORE_AVG = ((PV1MATH + PV1READ + PV1SCIE)/3)) %&gt;% \n  group_by(CNT) %&gt;% \n  mutate(CNT_AVG_SCORE = mean(SCORE_AVG)) %&gt;%\n  mutate(CNT_SD_SCORE = sd(SCORE_AVG)) %&gt;% \n  ungroup() %&gt;% \n  mutate(STU_REL_SCORE = ((SCORE_AVG-CNT_AVG_SCORE)/CNT_SD_SCORE)) %&gt;% \n  select(CNT, SCORE_AVG, CNT_AVG_SCORE, CNT_SD_SCORE, STU_REL_SCORE, WORKPAY,ESCS) %&gt;%\n  mutate(WORKPAY_numeric = \n           case_when(WORKPAY == \"No work for pay\" ~ 0,\n                     WORKPAY == \"1 time of working for pay per week\" ~ 1,\n                     WORKPAY == \"2 times of working for pay per week\" ~ 2,\n                     WORKPAY == \"3 times of working for pay per week\" ~ 3,\n                     WORKPAY == \"4 times of working for pay per week\" ~ 4,\n                     WORKPAY == \"5 times of working for pay per week\" ~ 5,\n                     WORKPAY == \"6 times of working for pay per week\" ~ 6,\n                     WORKPAY == \"7 times of working for pay per week\" ~ 7,\n                     WORKPAY == \"8 times of working for pay per week\" ~ 8,\n                     WORKPAY == \"9 times of working for pay per week\" ~ 9,\n                     WORKPAY == \"10 or more times of working for pay per week\" ~ NA,\n                     .default = NA)) %&gt;%\n  filter(!is.na(WORKPAY_numeric))\n\nggplot(data = avg_score,\n       aes(x=WORKPAY_numeric, y=STU_REL_SCORE)) +\n  geom_smooth(method = 'lm')+\n  scale_x_continuous(breaks = 0:10)+\n  ggtitle(\"How working affects student scores across the world\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  xlab(\"Number of times worked per week\") +\n  ylab(\"Student average score normalised relative to own country\") +\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\nWhich does show more clearly a negative correlation between times worked per week when times is less than 5. The correlation gets a little more noisy after that. I speculate this is because working more than 5 times per week would mean working more than every weekday, which might mean students answering the questionnaire with larger numbers may be defining a “working” period differently than those answering with smaller values or perhaps have misread the question making the data noisier for values over 5.\nOne thing in discussion with Peter and Richard I realised was that this model while it takes account of differences in economic status by country, it does not take into account differences in socioeconomic status between students. It is completely plausible that even within a country poorer students might be having to work more than richer ones, and it is fairly established that students with lower socioeconomic status get lower scores on PISA tests (Tessier 2018). This might mean that all we are seeing in this graph is that effect, rather than any effect from working in a job. To remedy this we can adapt our model to control for socioeconomic status (ESCS).\n\n\n\nFirst of all let’s see if there is a relationship between a student working in a job and their ESCS.\n\nescs_vs_work &lt;- PISA_2022 %&gt;% \n  select(WORKPAY, ESCS) %&gt;% \n  mutate(WORKPAY_numeric = \n           case_when(WORKPAY == \"No work for pay\" ~ 0,\n                     WORKPAY == \"1 time of working for pay per week\" ~ 1,\n                     WORKPAY == \"2 times of working for pay per week\" ~ 2,\n                     WORKPAY == \"3 times of working for pay per week\" ~ 3,\n                     WORKPAY == \"4 times of working for pay per week\" ~ 4,\n                     WORKPAY == \"5 times of working for pay per week\" ~ 5,\n                     WORKPAY == \"6 times of working for pay per week\" ~ 6,\n                     WORKPAY == \"7 times of working for pay per week\" ~ 7,\n                     WORKPAY == \"8 times of working for pay per week\" ~ 8,\n                     WORKPAY == \"9 times of working for pay per week\" ~ 9,\n                     WORKPAY == \"10 or more times of working for pay per week\" ~ NA,\n                     .default = NA)) %&gt;%\n  filter(!is.na(WORKPAY_numeric)) %&gt;% \n  filter(!is.na(ESCS))\n\nggplot(data = escs_vs_work,\n       aes(x=WORKPAY_numeric, y=ESCS)) +\n  geom_smooth(method = 'lm')+\n  scale_x_continuous(breaks = 0:10)+\n  ggtitle(\"Do low socioeconomic status students work more times a week?\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  xlab(\"Number of times worked per week\") +\n  ylab(\"Student socioeconomic status\") +\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\nClearly there is a negative correlation, students who work more times per week are also of lower socioeconomic status. An interesting aside that I cannot explain is that odd working times per week lower than 5 have higher ESCS and even working times above 5 have higher ESCS. I think this may be because the WORKPAY category is a composite category made from two questions “How many times in the last week did you work for pay after school?” and “How many times in the last week did you work for pay before school?” This is pure speculation but perhaps there is some difference in ESCS between students who work before and after school, and the way the two questions are being aggregated is showing that up. I could possibly use the full PISA data set to look at the responses to those individual questions but that would perhaps be a distraction from the current investigation.\nLet’s compare the correlations between WORKPAY and ESCS to see how much they are correlated.\n\ncor.test(escs_vs_work$WORKPAY_numeric, escs_vs_work$ESCS, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  escs_vs_work$WORKPAY_numeric and escs_vs_work$ESCS\nt = -50.101, df = 529231, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07138745 -0.06602455\nsample estimates:\n        cor \n-0.06870649 \n\n\nWhile the relationship is incredibly significant (p &lt; 2.2e-16), there is only a small negative correlation (-0.0687). Let’s compare this with the correlation between WORKPAY and STU_REL_SCORE.\n\ncor.test(avg_score$WORKPAY_numeric, avg_score$STU_REL_SCORE, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  avg_score$WORKPAY_numeric and avg_score$STU_REL_SCORE\nt = -163.69, df = 537551, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2204415 -0.2153489\nsample estimates:\n       cor \n-0.2178967 \n\n\nAgain an incredibly significant result (p &lt; 2.2e-16), but this time the correlation is more than 3 times greater (-0.218). We are not done as we should do a final correlation test between ESCS and STU_REL_SCORE to be able to see how much of a difference the two variables have compared to each other.\n\ncor.test(avg_score$ESCS, avg_score$STU_REL_SCORE, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  avg_score$ESCS and avg_score$STU_REL_SCORE\nt = 237.46, df = 529231, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3078603 0.3127298\nsample estimates:\n      cor \n0.3102971 \n\n\nOnce again incredibly significant (p &lt; 2.2e-16), the correlation is similar to the WORKPAY correlation but about 50% higher (0.310) and positive instead of negative. Given the negligible correlation between WORKPAY and ESCS and the weak to moderate correlations between WORKPAY, ESCS and STU_REL_SCORE we can be fairly confident that WORKPAY does have an effect on STU_REL_SCORE. However to find out how much of a effect WORKPAY is having we can do a multiple linear regression controlling for ESCS.\n\nlibrary(easystats)\nmodel &lt;- lm(STU_REL_SCORE ~ WORKPAY_numeric + ESCS,\n            data=avg_score)\nsummary(model)\n\n\nCall:\nlm(formula = STU_REL_SCORE ~ WORKPAY_numeric + ESCS, data = avg_score)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8889 -0.6290 -0.0027  0.6252  4.3940 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.2518582  0.0014245   176.8   &lt;2e-16 ***\nWORKPAY_numeric -0.1003225  0.0006479  -154.9   &lt;2e-16 ***\nESCS             0.2622097  0.0011323   231.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9163 on 529230 degrees of freedom\n  (8320 observations deleted due to missingness)\nMultiple R-squared:  0.1355,    Adjusted R-squared:  0.1355 \nF-statistic: 4.146e+04 on 2 and 529230 DF,  p-value: &lt; 2.2e-16\n\nreport(model)\n\nWe fitted a linear model (estimated using OLS) to predict STU_REL_SCORE with\nWORKPAY_numeric and ESCS (formula: STU_REL_SCORE ~ WORKPAY_numeric + ESCS). The\nmodel explains a statistically significant and moderate proportion of variance\n(R2 = 0.14, F(2, 529230) = 41459.59, p &lt; .001, adj. R2 = 0.14). The model's\nintercept, corresponding to WORKPAY_numeric = 0 and ESCS = 0, is at 0.25 (95%\nCI [0.25, 0.25], t(529230) = 176.81, p &lt; .001). Within this model:\n\n  - The effect of WORKPAY numeric is statistically significant and negative (beta\n= -0.10, 95% CI [-0.10, -0.10], t(529230) = -154.85, p &lt; .001; Std. beta =\n-0.20, 95% CI [-0.20, -0.20])\n  - The effect of ESCS is statistically significant and positive (beta = 0.26,\n95% CI [0.26, 0.26], t(529230) = 231.56, p &lt; .001; Std. beta = 0.30, 95% CI\n[0.29, 0.30])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nSo, even when taking into account the household socioeconomic status there is a small but significant effect of a student having to work during the weekdays. This model explains 14% of the variance in STU_REL_SCORE. Combined with the discoveries above that WORKPAY has little correlation with ESCS we can be fairly confident in it’s effect on student outcomes.\nTo summarise; maybe if I hadn’t worked at Homebase when I was 17 years old I’d have got an A in my chemistry A-level instead of a B."
  },
  {
    "objectID": "posts/Scottish STEM/ScottishSTEM.html",
    "href": "posts/Scottish STEM/ScottishSTEM.html",
    "title": "Scottish STEM",
    "section": "",
    "text": "Add what you did here"
  },
  {
    "objectID": "posts/Scottish STEM/ScottishSTEM.html#scottish-stem-uptake",
    "href": "posts/Scottish STEM/ScottishSTEM.html#scottish-stem-uptake",
    "title": "Scottish STEM",
    "section": "",
    "text": "Add what you did here"
  },
  {
    "objectID": "posts/Scottish STEM/ScottishSTEM.html#my-code",
    "href": "posts/Scottish STEM/ScottishSTEM.html#my-code",
    "title": "Scottish STEM",
    "section": "My code",
    "text": "My code\n\n# Add your code here"
  },
  {
    "objectID": "posts/Scottish STEM/ScottishSTEM.html#what-it-means",
    "href": "posts/Scottish STEM/ScottishSTEM.html#what-it-means",
    "title": "Scottish STEM",
    "section": "What it means",
    "text": "What it means\nAdd your thoughts here"
  },
  {
    "objectID": "posts/GenderKaty/GenderKaty.html",
    "href": "posts/GenderKaty/GenderKaty.html",
    "title": "Gender differences in PISA",
    "section": "",
    "text": "I wanted to compare the maths and reading scores and then the science and maths scores and see if there were any gender differences. As expected for both comparisons there is a positive correlation for both genders. There is not much difference between the line of best fit when comparing science and maths, maybe to be expected: as it is a similar skill set? However, looking at the comparison of the reading and maths scores, it is interesting to note that as the scores increase the distance between the line of best fit for different genders increases, slightly so that the males are slightly higher in maths scores compared to females.\n\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\n\n\nmaths_read &lt;- PISA_2022 %&gt;%\n select(ST004D01T, PV1READ, PV1MATH)%&gt;%\n na.omit()\n\nggplot (data =maths_read, aes (x= PV1READ, y =PV1MATH, colour = ST004D01T)) +\ngeom_point(size =0.1) +\ngeom_smooth(method = 'lm') +\nxlab(\"Read Score\") + \nylab(\"Maths Score\") +\nggtitle(\"Comparision of maths and read score, by gender\") +\ntheme(legend.position = \"bottom\") +\nlabs(colour =\"Gender\")\n\n\n\n\n\nmaths_sci &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, PV1SCIE, PV1MATH)%&gt;%\n  na.omit()\n\nggplot(data = maths_sci, aes(x = PV1SCIE, y =PV1MATH, colour = ST004D01T)) +\n geom_point(size =0.1) +\n geom_smooth(method = 'lm') +\n xlab(\"science Score\") +\n ylab(\"Maths Score\") +\n ggtitle(\"Comparision of maths and science Score, by gender\")+\n theme(legend.position = \"bottom\")+\n labs(colour=\"Gender\")\n\n\n\n\nI then wanted to see if the United Kingdom followed the same pattern. There are similar trends, but the gap between female and male reading and maths scores starts a little earlier.\n\nmaths_read_UK &lt;- PISA_2022 %&gt;%\n select(ST004D01T, PV1READ, PV1MATH, CNT)%&gt;%\n na.omit() %&gt;%\n filter (CNT == \"United Kingdom\")\n\nggplot (data =maths_read_UK, aes(x= PV1READ, y =PV1MATH, colour = ST004D01T))+\ngeom_point(size =0.1) +\ngeom_smooth (method = 'lm')+\nxlab(\"Read Score\")+ \nylab(\"Maths Score\")+\nggtitle(\"Comparision of maths and read Score, by gender, in United Kingdom\")+\ntheme(legend.position = \"bottom\")+\nlabs(colour =\"Gender\")\n\n\n\n\nThen I wanted to see the trends using a bar chart, as I wondered if this would be clearer. In all countries there is a higher % of males that have maths scores better than reading scores.\n\nmaths_better &lt;- PISA_2022 %&gt;%\n mutate(maths_better = PV1READ&lt; PV1MATH) %&gt;%\n select(ST004D01T, PV1READ, PV1MATH, CNT, maths_better) %&gt;%\n filter(!is.na(ST004D01T),!is.na(maths_better)) %&gt;%\n group_by (ST004D01T, CNT) %&gt;%\n mutate(students_n = n()) %&gt;%\n filter(maths_better ==\"TRUE\") %&gt;% \ngroup_by (ST004D01T, CNT, maths_better) %&gt;%\n   summarise(n =n(),\n             per = 100*n/unique(students_n))\n\nmaths_bettersci &lt;- PISA_2022 %&gt;%\n  mutate(maths_better = PV1SCIE&lt; PV1MATH) %&gt;%\n  select(ST004D01T, PV1SCIE, PV1MATH, CNT, maths_better) %&gt;%  \n  filter(!is.na(ST004D01T),!is.na(maths_better)) %&gt;%\n  group_by (ST004D01T, CNT) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  filter(maths_better ==\"TRUE\") %&gt;% \n  group_by(ST004D01T, CNT, maths_better) %&gt;% \n  summarise(n =n(), \n            per = 100*n/unique(students_n))\n  \nggplot(data = maths_bettersci, \n       aes (x = CNT, y = per))+\ngeom_bar(aes(fill = ST004D01T), \n         position = position_dodge(),\n        stat=\"identity\") +\ntheme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\ntheme(legend.position = \"bottom\") +\nxlab(\"Country\") +\nylab(\"% students maths better than science\") +\nggtitle(\"Comparision of maths and science score, by country and gender\") + \nlabs(fill =\"Gender\")\n\n\n\n\nI then looked at comparing maths and science scores. It is interesting that there is not so much of a gender difference, it would appear that the % of males doing better in maths compared to science and read are similar, but when comparing science to maths, here the % of females who do better in maths when compared to science is higher than when compared to read. Then comparing reading and science scores. This time % read was better. Here the % of females for every country is higher than male. It appears as if there is an international trend generally.\n\nread_bettersci &lt;- PISA_2022 %&gt;%\n mutate(read_better = PV1SCIE&lt; PV1READ) %&gt;%\n select(ST004D01T, PV1SCIE, PV1READ, CNT, read_better) %&gt;% \n filter(!is.na(ST004D01T),!is.na(read_better)) %&gt;%\n group_by (ST004D01T, CNT) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  filter(read_better ==\"TRUE\")%&gt;% \n  group_by(ST004D01T, CNT, read_better) %&gt;%\n  summarise(n=n(),\n  per = 100*n/unique(students_n))\n\nggplot(data =read_bettersci, aes(x=CNT, y= per))+\ngeom_bar(aes(fill = ST004D01T),\n         position=position_dodge(), \n        stat='identity')+\ntheme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\ntheme(legend.position = \"bottom\") +\nxlab(\"Country\") +\nylab(\"% students read better than science\") +\nggtitle(\"Comparision of read and science score, by country and gender\")+ \nlabs(fill =\"Gender\")"
  },
  {
    "objectID": "posts/GenderKaty/GenderKaty.html#pisa-gender-achievment-differences",
    "href": "posts/GenderKaty/GenderKaty.html#pisa-gender-achievment-differences",
    "title": "Gender differences in PISA",
    "section": "",
    "text": "Here are my graphs for the challenge: I wanted to compare Maths and Read Scores and then the Science and Maths Scores.\nAs expected for both comparisons there is a positive correlation for both genders. There is not much difference between the line of best fit when comparing science and maths, maybe to be expected: similar skill set?\nHowever, the comparison of reading and maths score, it is interesting to note that as the scores increase the distance between the line of best fit for different genders increases, slightly so that the males are slightly higher in maths scores compared to female?\n\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\n\n\nmaths_read &lt;- PISA_2022 %&gt;%\n select(ST004D01T, PV1READ, PV1MATH)%&gt;%\n na.omit()\n\nggplot (data =maths_read, aes (x= PV1READ, y =PV1MATH, colour = ST004D01T)) +\ngeom_point(size =0.1) +\ngeom_smooth(method = 'lm') +\nxlab(\"Read Score\") + \nylab(\"Maths Score\") +\nggtitle(\"Comparision of maths and read score, by gender\") +\ntheme(legend.position = \"bottom\") +\nlabs(colour =\"Gender\")\n\n\n\n\n\nmaths_sci &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, PV1SCIE, PV1MATH)%&gt;%\n  na.omit()\n\nggplot(data = maths_sci, aes(x = PV1SCIE, y =PV1MATH, colour = ST004D01T)) +\n geom_point(size =0.1) +\n geom_smooth(method = 'lm') +\n xlab(\"science Score\") +\n ylab(\"Maths Score\") +\n ggtitle(\"Comparision of maths and science Score, by gender\")+\n theme(legend.position = \"bottom\")+\n labs(colour=\"Gender\")\n\n\n\n\nI then wanted to see if the United Kingdom followed the same pattern, similar trends, but gap between female and male read and maths starts a little earlier\n\nmaths_read_UK &lt;- PISA_2022 %&gt;%\n select(ST004D01T, PV1READ, PV1MATH, CNT)%&gt;%\n na.omit() %&gt;%\n filter (CNT == \"United Kingdom\")\n\nggplot (data =maths_read_UK, aes(x= PV1READ, y =PV1MATH, colour = ST004D01T))+\ngeom_point(size =0.1) +\ngeom_smooth (method = 'lm')+\nxlab(\"Read Score\")+ \nylab(\"Maths Score\")+\nggtitle(\"Comparision of maths and read Score, by gender, in United Kingdom\")+\ntheme(legend.position = \"bottom\")+\nlabs(colour =\"Gender\")\n\n\n\n\nThen wanted to see it using a bar chart, as wondered if this would be clearer In all countries there is a higher % of males that have maths scores better than read.\n\nmaths_better &lt;- PISA_2022 %&gt;%\n mutate(maths_better = PV1READ&lt; PV1MATH) %&gt;%\n select(ST004D01T, PV1READ, PV1MATH, CNT, maths_better) %&gt;%\n filter(!is.na(ST004D01T),!is.na(maths_better)) %&gt;%\n group_by (ST004D01T, CNT) %&gt;%\n mutate(students_n = n()) %&gt;%\n filter(maths_better ==\"TRUE\") %&gt;% \ngroup_by (ST004D01T, CNT, maths_better) %&gt;%\n   summarise(n =n(),\n             per = 100*n/unique(students_n))\n\nmaths_bettersci &lt;- PISA_2022 %&gt;%\n  mutate(maths_better = PV1SCIE&lt; PV1MATH) %&gt;%\n  select(ST004D01T, PV1SCIE, PV1MATH, CNT, maths_better) %&gt;%  \n  filter(!is.na(ST004D01T),!is.na(maths_better)) %&gt;%\n  group_by (ST004D01T, CNT) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  filter(maths_better ==\"TRUE\") %&gt;% \n  group_by(ST004D01T, CNT, maths_better) %&gt;% \n  summarise(n =n(), \n            per = 100*n/unique(students_n))\n  \nggplot(data = maths_bettersci, \n       aes (x = CNT, y = per))+\ngeom_bar(aes(fill = ST004D01T), \n         position = position_dodge(),\n        stat=\"identity\") +\ntheme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\ntheme(legend.position = \"bottom\") +\nxlab(\"Country\") +\nylab(\"% students maths better than science\") +\nggtitle(\"Comparision of maths and science score, by country and gender\") + \nlabs(fill =\"Gender\")\n\n\n\n\nI wanted to then see the trend comparing maths and science. It is interesting that there is not so much of a gender difference, it would appear that the male% doing better in maths compared to science and read are similar, but when comparing science to maths, here the females % who do better in maths when compared to science is higher than when compared to read.\nThen comparing read and science. This time % read better. Here the % of female for every country is higher than the male.\n\nread_bettersci &lt;- PISA_2022 %&gt;%\n mutate(read_better = PV1SCIE&lt; PV1READ) %&gt;%\n select(ST004D01T, PV1SCIE, PV1READ, CNT, read_better) %&gt;% \n filter(!is.na(ST004D01T),!is.na(read_better)) %&gt;%\n group_by (ST004D01T, CNT) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  filter(read_better ==\"TRUE\")%&gt;% \n  group_by(ST004D01T, CNT, read_better) %&gt;%\n  summarise(n=n(),\n  per = 100*n/unique(students_n))\n\nggplot(data =read_bettersci, aes(x=CNT, y= per))+\ngeom_bar(aes(fill = ST004D01T),\n         position=position_dodge(), \n        stat='identity')+\ntheme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\ntheme(legend.position = \"bottom\") +\nxlab(\"Country\") +\nylab(\"% students read better than science\") +\nggtitle(\"Comparision of read and science score, by country and gender\")+ \nlabs(fill =\"Gender\")"
  },
  {
    "objectID": "posts/GenderAaron/GenderAaron.html",
    "href": "posts/GenderAaron/GenderAaron.html",
    "title": "Gender differences",
    "section": "",
    "text": "Here is the code:\n\nlibrary(arrow)\nlibrary(tidyverse)\nlibrary(cowplot)\n\n#PISA_2022 &lt;- read_parquet(\"\")\n\n# Add your code with comments here please"
  },
  {
    "objectID": "posts/GenderAaron/GenderAaron.html#pisa-gender-achievment-differences-between-oecd-and-non-oecd-countries",
    "href": "posts/GenderAaron/GenderAaron.html#pisa-gender-achievment-differences-between-oecd-and-non-oecd-countries",
    "title": "Gender differences",
    "section": "",
    "text": "Here is the code:\n\nlibrary(arrow)\nlibrary(tidyverse)\nlibrary(cowplot)\n\n#PISA_2022 &lt;- read_parquet(\"\")\n\n# Add your code with comments here please"
  },
  {
    "objectID": "posts/GenderKaty/GenderKaty.html#gender-differences-in-pisa2022-data",
    "href": "posts/GenderKaty/GenderKaty.html#gender-differences-in-pisa2022-data",
    "title": "Gender differences in PISA",
    "section": "",
    "text": "I wanted to compare the maths and reading scores and then the science and maths scores and see if there were any gender differences. As expected for both comparisons there is a positive correlation for both genders. There is not much difference between the line of best fit when comparing science and maths, maybe to be expected: as it is a similar skill set? However, looking at the comparison of the reading and maths scores, it is interesting to note that as the scores increase the distance between the line of best fit for different genders increases, slightly so that the males are slightly higher in maths scores compared to females.\n\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\n\n\nmaths_read &lt;- PISA_2022 %&gt;%\n select(ST004D01T, PV1READ, PV1MATH)%&gt;%\n na.omit()\n\nggplot (data =maths_read, aes (x= PV1READ, y =PV1MATH, colour = ST004D01T)) +\ngeom_point(size =0.1) +\ngeom_smooth(method = 'lm') +\nxlab(\"Read Score\") + \nylab(\"Maths Score\") +\nggtitle(\"Comparision of maths and read score, by gender\") +\ntheme(legend.position = \"bottom\") +\nlabs(colour =\"Gender\")\n\n\n\n\n\nmaths_sci &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, PV1SCIE, PV1MATH)%&gt;%\n  na.omit()\n\nggplot(data = maths_sci, aes(x = PV1SCIE, y =PV1MATH, colour = ST004D01T)) +\n geom_point(size =0.1) +\n geom_smooth(method = 'lm') +\n xlab(\"science Score\") +\n ylab(\"Maths Score\") +\n ggtitle(\"Comparision of maths and science Score, by gender\")+\n theme(legend.position = \"bottom\")+\n labs(colour=\"Gender\")\n\n\n\n\nI then wanted to see if the United Kingdom followed the same pattern. There are similar trends, but the gap between female and male reading and maths scores starts a little earlier.\n\nmaths_read_UK &lt;- PISA_2022 %&gt;%\n select(ST004D01T, PV1READ, PV1MATH, CNT)%&gt;%\n na.omit() %&gt;%\n filter (CNT == \"United Kingdom\")\n\nggplot (data =maths_read_UK, aes(x= PV1READ, y =PV1MATH, colour = ST004D01T))+\ngeom_point(size =0.1) +\ngeom_smooth (method = 'lm')+\nxlab(\"Read Score\")+ \nylab(\"Maths Score\")+\nggtitle(\"Comparision of maths and read Score, by gender, in United Kingdom\")+\ntheme(legend.position = \"bottom\")+\nlabs(colour =\"Gender\")\n\n\n\n\nThen I wanted to see the trends using a bar chart, as I wondered if this would be clearer. In all countries there is a higher % of males that have maths scores better than reading scores.\n\nmaths_better &lt;- PISA_2022 %&gt;%\n mutate(maths_better = PV1READ&lt; PV1MATH) %&gt;%\n select(ST004D01T, PV1READ, PV1MATH, CNT, maths_better) %&gt;%\n filter(!is.na(ST004D01T),!is.na(maths_better)) %&gt;%\n group_by (ST004D01T, CNT) %&gt;%\n mutate(students_n = n()) %&gt;%\n filter(maths_better ==\"TRUE\") %&gt;% \ngroup_by (ST004D01T, CNT, maths_better) %&gt;%\n   summarise(n =n(),\n             per = 100*n/unique(students_n))\n\nmaths_bettersci &lt;- PISA_2022 %&gt;%\n  mutate(maths_better = PV1SCIE&lt; PV1MATH) %&gt;%\n  select(ST004D01T, PV1SCIE, PV1MATH, CNT, maths_better) %&gt;%  \n  filter(!is.na(ST004D01T),!is.na(maths_better)) %&gt;%\n  group_by (ST004D01T, CNT) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  filter(maths_better ==\"TRUE\") %&gt;% \n  group_by(ST004D01T, CNT, maths_better) %&gt;% \n  summarise(n =n(), \n            per = 100*n/unique(students_n))\n  \nggplot(data = maths_bettersci, \n       aes (x = CNT, y = per))+\ngeom_bar(aes(fill = ST004D01T), \n         position = position_dodge(),\n        stat=\"identity\") +\ntheme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\ntheme(legend.position = \"bottom\") +\nxlab(\"Country\") +\nylab(\"% students maths better than science\") +\nggtitle(\"Comparision of maths and science score, by country and gender\") + \nlabs(fill =\"Gender\")\n\n\n\n\nI then looked at comparing maths and science scores. It is interesting that there is not so much of a gender difference, it would appear that the % of males doing better in maths compared to science and read are similar, but when comparing science to maths, here the % of females who do better in maths when compared to science is higher than when compared to read. Then comparing reading and science scores. This time % read was better. Here the % of females for every country is higher than male. It appears as if there is an international trend generally.\n\nread_bettersci &lt;- PISA_2022 %&gt;%\n mutate(read_better = PV1SCIE&lt; PV1READ) %&gt;%\n select(ST004D01T, PV1SCIE, PV1READ, CNT, read_better) %&gt;% \n filter(!is.na(ST004D01T),!is.na(read_better)) %&gt;%\n group_by (ST004D01T, CNT) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  filter(read_better ==\"TRUE\")%&gt;% \n  group_by(ST004D01T, CNT, read_better) %&gt;%\n  summarise(n=n(),\n  per = 100*n/unique(students_n))\n\nggplot(data =read_bettersci, aes(x=CNT, y= per))+\ngeom_bar(aes(fill = ST004D01T),\n         position=position_dodge(), \n        stat='identity')+\ntheme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\ntheme(legend.position = \"bottom\") +\nxlab(\"Country\") +\nylab(\"% students read better than science\") +\nggtitle(\"Comparision of read and science score, by country and gender\")+ \nlabs(fill =\"Gender\")"
  },
  {
    "objectID": "posts/USUKMaths/USUKMaths.html",
    "href": "posts/USUKMaths/USUKMaths.html",
    "title": "Differences in PISA mathematics scores in the US and UK",
    "section": "",
    "text": "In this graph, we compare the PISA Math scores for two countries, the United Kingdom and the United States, and filter them by gender.\n\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\n\n\nMathplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T)%&gt;%\n  filter(CNT == \"United States\" | CNT == \"United Kingdom\")%&gt;%\n  na.omit()\nggplot(Mathplot, aes(x = PV1MATH, fill = ST004D01T)) +\n    geom_density(alpha = 0.6) +\n    facet_wrap(. ~ CNT)\n\n\n\n\nEach part of the graph has hill-shaped lines, one in pink and one in teal, representing the students’ math scores. The pink lines represent the female students, and the teal line shows the results for male students (no gender bias here – intentionally!).\nThe x-axis shows the math scores, and the y-axis shows the density. A higher up on the axis would mean that more students go that score. Both countries show a similar distribution, clustering around the range’s middle. In both the UK and the US, the peaks of the male density curves are very close, suggesting that the average math scores for both genders are similar. The spread of the scores (from the lowest to the highest) seems similar for both genders in each country, meaning there’s a similar range of performance within both genders. There is also a significant overlap between the scores for males and females, which indicates that many students from both genders have similar math performances.\nThe graph doesn’t show a stark difference between the two countries based on the density peaks; both countries have their peaks at a similar score range, indicating comparable average math abilities."
  },
  {
    "objectID": "posts/USUKMaths/USUKMaths.html#mathematics-scores-in-the-us-and-the-uk",
    "href": "posts/USUKMaths/USUKMaths.html#mathematics-scores-in-the-us-and-the-uk",
    "title": "Differences in PISA mathematics scores in the US and UK",
    "section": "",
    "text": "In this graph, we compare the PISA Math scores for two countries, the United Kingdom and the United States, and filter them by gender.\n\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\n\n\nMathplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T)%&gt;%\n  filter(CNT == \"United States\" | CNT == \"United Kingdom\")%&gt;%\n  na.omit()\nggplot(Mathplot, aes(x = PV1MATH, fill = ST004D01T)) +\n    geom_density(alpha = 0.6) +\n    facet_wrap(. ~ CNT)\n\n\n\n\nEach part of the graph has hill-shaped lines, one in pink and one in teal, representing the students’ math scores. The pink lines represent the female students, and the teal line shows the results for male students (no gender bias here – intentionally!).\nThe x-axis shows the math scores, and the y-axis shows the density. A higher up on the axis would mean that more students go that score. Both countries show a similar distribution, clustering around the range’s middle. In both the UK and the US, the peaks of the male density curves are very close, suggesting that the average math scores for both genders are similar. The spread of the scores (from the lowest to the highest) seems similar for both genders in each country, meaning there’s a similar range of performance within both genders. There is also a significant overlap between the scores for males and females, which indicates that many students from both genders have similar math performances.\nThe graph doesn’t show a stark difference between the two countries based on the density peaks; both countries have their peaks at a similar score range, indicating comparable average math abilities."
  },
  {
    "objectID": "posts/PaternalEducation/PaternalEducation.html",
    "href": "posts/PaternalEducation/PaternalEducation.html",
    "title": "Who’s Better Educated, Mum or Dad?",
    "section": "",
    "text": "This post looks into the differences between mother’s and father’s education levels across the world. Do mothers or fathers have higher education levels. Do people tend to partner up with people who have a similar education level to themselves?\nPISA use the ISCED international educational comparison system (OECD 2011). PISA only ask about the first 4 education levels though, 0,1,2 and 3. The highest level, level 3, corresponds to having completed the country’s equivalent of high school. PISA split the level 3 grouping into 3.3 and 3.4. which relate to vocational and non-vocational education types both at high school level (OECD 2022).\nFirst let’s investigate the world distribution of education levels and answer our two questions about the world as a whole.\n\nlibrary(arrow)\nlibrary(tidyverse)\nlibrary(ggmosaic)\nlibrary(viridis)\nlibrary(gt)\n \nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\n\n \nc5 &lt;- PISA_2022 %&gt;% \n  filter(!is.na(ST005Q01JA)&!is.na(ST007Q01JA)) %&gt;% \n  select(CNT, ST005Q01JA, ST007Q01JA) %&gt;% \n  droplevels()\n \nc5 &lt;- rename(c5, MOTHERED = ST005Q01JA, FATHERED = ST007Q01JA)\n \nlevels(c5$MOTHERED) &lt;- c(\"Level 3.4\", \"Level 3.3\", \"Level 2\", \"Level 1\", \"No Completion\")\nlevels(c5$FATHERED) &lt;- c(\"Level 3.4\", \"Level 3.3\", \"Level 2\", \"Level 1\", \"No Completion\")\n \nc5$MOTHERED &lt;- factor(c5$MOTHERED, levels = rev(levels(c5$MOTHERED)))\nc5$FATHERED &lt;- factor(c5$FATHERED, levels = rev(levels(c5$FATHERED)))\n \nconttab &lt;- xtabs(data = c5, ~ MOTHERED + FATHERED)\nconttab\n\n               FATHERED\nMOTHERED        No Completion Level 1 Level 2 Level 3.3 Level 3.4\n  No Completion          7742    3846    3205       969      3225\n  Level 1                3132   12452    7364      2075      6945\n  Level 2                3122    7437   38007      8766     21953\n  Level 3.3              1131    2479    9878     58929     24510\n  Level 3.4              3719    6854   29751     40710    250006\n\nggplot(data = c5) +     \n  geom_mosaic(aes(x = product(MOTHERED, FATHERED), fill = MOTHERED)) +\n  xlab(\"MOTHERED\") +\n  ylab(\"FATHERED\")+\n  theme(legend.position = \"none\")+\n  scale_fill_viridis(discrete = TRUE)+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\nSo on average pupils’ fathers’ distribution of level of education is generally higher than their mothers’ distribution however the largest groupings are for situations where the father’s and mother’s education is the same. So worldwide we have a visible education inequality between women and men, but also we have the interesting finding that people tend to partner up with those that have similar education levels to themselves.\nGiven the highest level measured is high school this seems to make sense, it is easy to imagine people meeting each other and creating their social networks in school, leaving school early together or staying in school for longer together and then eventually pairing up with people from those exact social networks, at least that’s my hypothesis, further investigation would be needed; perhaps PISA could include a question on their next parental survey: “sooooo, how’d you two meet??”\nThe mosaic plot does make the distributions look significantly different, but let’s test for significance anyway and see just how significant the finding is.\n\nchisq.test(conttab)\n\n\n    Pearson's Chi-squared test\n\ndata:  conttab\nX-squared = 392771, df = 16, p-value &lt; 2.2e-16\n\n\np = 2.2e-16 which is far less than 0.05 so the result is statistically significant, however the level of education variable is ordinal, Chi-Square will work on ordinal data but a Kruskal Wallis test is arguably more appropriate as it takes into account the ordinal nature of the data.\n\nkruskal.test(data = c5, MOTHERED ~ FATHERED)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  MOTHERED by FATHERED\nKruskal-Wallis chi-squared = 158276, df = 4, p-value &lt; 2.2e-16\n\n\np-value = 2.2e-16 which again is far less than 0.05 so the result is statistically significant. This means mothers’ and fathers’ distributions of education level are not equal there is a significant variance between education levels."
  },
  {
    "objectID": "posts/PaternalEducation/PaternalEducation.html#mothers-and-fathers-occupations",
    "href": "posts/PaternalEducation/PaternalEducation.html#mothers-and-fathers-occupations",
    "title": "Who’s Better Educated, Mum or Dad?",
    "section": "",
    "text": "This post looks into the differences between mother’s and father’s education levels across the world. Do mothers or fathers have higher education levels. Do people tend to partner up with people who have a similar education level to themselves?\nPISA use the ISCED international educational comparison system (OECD 2011). PISA only ask about the first 4 education levels though, 0,1,2 and 3. The highest level, level 3, corresponds to having completed the country’s equivalent of high school. PISA split the level 3 grouping into 3.3 and 3.4. which relate to vocational and non-vocational education types both at high school level (OECD 2022).\nFirst let’s investigate the world distribution of education levels and answer our two questions about the world as a whole.\n\nlibrary(arrow)\nlibrary(tidyverse)\nlibrary(ggmosaic)\nlibrary(viridis)\nlibrary(gt)\n \nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\n\n \nc5 &lt;- PISA_2022 %&gt;% \n  filter(!is.na(ST005Q01JA)&!is.na(ST007Q01JA)) %&gt;% \n  select(CNT, ST005Q01JA, ST007Q01JA) %&gt;% \n  droplevels()\n \nc5 &lt;- rename(c5, MOTHERED = ST005Q01JA, FATHERED = ST007Q01JA)\n \nlevels(c5$MOTHERED) &lt;- c(\"Level 3.4\", \"Level 3.3\", \"Level 2\", \"Level 1\", \"No Completion\")\nlevels(c5$FATHERED) &lt;- c(\"Level 3.4\", \"Level 3.3\", \"Level 2\", \"Level 1\", \"No Completion\")\n \nc5$MOTHERED &lt;- factor(c5$MOTHERED, levels = rev(levels(c5$MOTHERED)))\nc5$FATHERED &lt;- factor(c5$FATHERED, levels = rev(levels(c5$FATHERED)))\n \nconttab &lt;- xtabs(data = c5, ~ MOTHERED + FATHERED)\nconttab\n\n               FATHERED\nMOTHERED        No Completion Level 1 Level 2 Level 3.3 Level 3.4\n  No Completion          7742    3846    3205       969      3225\n  Level 1                3132   12452    7364      2075      6945\n  Level 2                3122    7437   38007      8766     21953\n  Level 3.3              1131    2479    9878     58929     24510\n  Level 3.4              3719    6854   29751     40710    250006\n\nggplot(data = c5) +     \n  geom_mosaic(aes(x = product(MOTHERED, FATHERED), fill = MOTHERED)) +\n  xlab(\"MOTHERED\") +\n  ylab(\"FATHERED\")+\n  theme(legend.position = \"none\")+\n  scale_fill_viridis(discrete = TRUE)+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\nSo on average pupils’ fathers’ distribution of level of education is generally higher than their mothers’ distribution however the largest groupings are for situations where the father’s and mother’s education is the same. So worldwide we have a visible education inequality between women and men, but also we have the interesting finding that people tend to partner up with those that have similar education levels to themselves.\nGiven the highest level measured is high school this seems to make sense, it is easy to imagine people meeting each other and creating their social networks in school, leaving school early together or staying in school for longer together and then eventually pairing up with people from those exact social networks, at least that’s my hypothesis, further investigation would be needed; perhaps PISA could include a question on their next parental survey: “sooooo, how’d you two meet??”\nThe mosaic plot does make the distributions look significantly different, but let’s test for significance anyway and see just how significant the finding is.\n\nchisq.test(conttab)\n\n\n    Pearson's Chi-squared test\n\ndata:  conttab\nX-squared = 392771, df = 16, p-value &lt; 2.2e-16\n\n\np = 2.2e-16 which is far less than 0.05 so the result is statistically significant, however the level of education variable is ordinal, Chi-Square will work on ordinal data but a Kruskal Wallis test is arguably more appropriate as it takes into account the ordinal nature of the data.\n\nkruskal.test(data = c5, MOTHERED ~ FATHERED)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  MOTHERED by FATHERED\nKruskal-Wallis chi-squared = 158276, df = 4, p-value &lt; 2.2e-16\n\n\np-value = 2.2e-16 which again is far less than 0.05 so the result is statistically significant. This means mothers’ and fathers’ distributions of education level are not equal there is a significant variance between education levels."
  },
  {
    "objectID": "posts/PaternalEducation/PaternalEducation.html#extension---analysis-by-country",
    "href": "posts/PaternalEducation/PaternalEducation.html#extension---analysis-by-country",
    "title": "Who’s Better Educated, Mum or Dad?",
    "section": "Extension - Analysis By Country",
    "text": "Extension - Analysis By Country\nHaving looked at the world data, an obvious interesting question is: Which countries are most equal? Are there any countries in which mothers have greater education levels than fathers on average? To do this I first have to convert the ISCED data into numeric levels so “Level 3.4” becomes simply the number 3. Then for each pupil I subtract the mother’s education level from the father’s education level to get a difference in education, with zero meaning no difference, a positive number meaning the father has a higher education level than the mother, and a negative number meaning the mother has a higher education level than the father. I then group by country and get the country mean for each country. I then print out every 4th country including the first and last country in the ordered list.\n\nlevels(c5$MOTHERED) &lt;- c(3, 3, 2, 1, 0)\nlevels(c5$FATHERED) &lt;- c(3, 3, 2, 1, 0)\n \nc5_means&lt;-c5 %&gt;% \n  mutate(MOTHERED_numeric = as.numeric(as.character(MOTHERED))) %&gt;% \n  mutate(FATHERED_numeric = as.numeric(as.character(FATHERED))) %&gt;% \n  mutate(parent_diff = FATHERED_numeric - MOTHERED_numeric) %&gt;% \n  group_by(CNT) %&gt;% \n  summarise(mean_diff = mean(parent_diff)) %&gt;% \n  arrange(mean_diff)\n \n \nrows_to_print &lt;- seq(1, 79, by = 4)\n \nif (!79 %in% rows_to_print) {\n  rows_to_print &lt;- c(rows_to_print, 79)\n}\n \nselected_rows &lt;- c5_means[rows_to_print, ]\n#print(selected_rows, n = 100)\n\n# To make a nice looking table\nselected_rows %&gt;%\n  gt() %&gt;% \n  fmt_number(mean_diff, decimals=4) %&gt;% \n  tab_header(\n    title = \"Country Equality, Small Selection\",\n    subtitle = \"Countries with better educated mothers have negative values, countries with better educated fathers have positive values.\"\n  ) %&gt;% \n  cols_label(\n    CNT = \"Country\",\n    mean_diff = \"Parental Education Difference\",\n    # add more columns as needed\n  )\n\n\n\n\n\n  \n    \n      Country Equality, Small Selection\n    \n    \n      Countries with better educated mothers have negative values, countries with better educated fathers have positive values.\n    \n    \n      Country\n      Parental Education Difference\n    \n  \n  \n    Türkiye\n−0.3976\n    Cambodia\n−0.1981\n    Qatar\n−0.1418\n    Viet Nam\n−0.0689\n    Kazakhstan\n−0.0225\n    Montenegro\n0.0102\n    Austria\n0.0229\n    Brunei Darussalam\n0.0355\n    United States\n0.0528\n    Thailand\n0.0657\n    Republic of Moldova\n0.0845\n    Palestinian Authority\n0.0956\n    Greece\n0.1146\n    Latvia\n0.1303\n    Mongolia\n0.1556\n    Australia\n0.1661\n    Italy\n0.1724\n    Ukrainian regions (18 of 27)\n0.2008\n    Spain\n0.2310\n    Uruguay\n0.2577\n    Portugal\n0.2982"
  },
  {
    "objectID": "posts/PaternalEducation/PaternalEducation.html#conclusion",
    "href": "posts/PaternalEducation/PaternalEducation.html#conclusion",
    "title": "Who’s Better Educated, Mum or Dad?",
    "section": "Conclusion",
    "text": "Conclusion\nI find this quite surprising. If you had asked me before conducting my analysis “which country has the most significant educational disparity where fathers are more educated than mothers?” I wouldn’t have guessed Portugal. Yet, my findings show that, Portugal exhibits the largest gap in favour of fathers’ educational attainment, however Portugal scores highly in the world economic forum’s measure of gender equality, WEF GGGI (WEF 2024).\nTurkey having the greatest educational attainment gap in favour of mothers is also surprising and perhaps works against our preconceptions related to gender equality particularly given it is a fairly low scoring country on the WEF GGGI. In fact, if you had asked me “which country has the most educational disparity where mothers are more educated than fathers?” before me doing the analysis I would have almost certainly have said one of the Scandinavian countries would have the greatest equality between father’s and mother’s educational levels in. However, Norway, Sweden, Denmark and Finland all appear well above the median value indicating a less equitable situation than you might guess in fact Iceland which has been in first place for 12 years on the WEF GGGI comes in at 8th worst using this metric. Countries that sometimes face criticism for their lack of equality for women actually score well on this metric, Turkey in 1st place, Morocco in 3rd place, Saudi Arabia in 6th place and Qatar in 9th place for having higher educational outcomes than fathers. I am not sure exactly what to take from this. Perhaps that my metric is not a good one for measuring equality, or provides a narrow view of equality as it compares mothers and fathers rather than women and men. What can be said though is that equality is a multi-faceted issue and one that we must all keep working on and must be wary of viewing it through a purely westernised lens.\n\nAppendix\n\nAll Country’s Scores\n\nlevels(c5$MOTHERED) &lt;- c(3, 3, 2, 1, 0)\nlevels(c5$FATHERED) &lt;- c(3, 3, 2, 1, 0)\n \nc5_means&lt;-c5 %&gt;% \n  mutate(MOTHERED_numeric = as.numeric(as.character(MOTHERED))) %&gt;% \n  mutate(FATHERED_numeric = as.numeric(as.character(FATHERED))) %&gt;% \n  mutate(parent_diff = FATHERED_numeric - MOTHERED_numeric) %&gt;% \n  group_by(CNT) %&gt;% \n  summarise(mean_diff = mean(parent_diff)) %&gt;% \n  arrange(mean_diff)\n \n \nrows_to_print &lt;- seq(1, 79, by = 1)\n \nif (!79 %in% rows_to_print) {\n  rows_to_print &lt;- c(rows_to_print, 79)\n}\n \nselected_rows &lt;- c5_means[rows_to_print, ]\n#print(selected_rows, n = 100)\n\n# To make a nice looking table\nselected_rows %&gt;%\n  gt() %&gt;% \n  fmt_number(mean_diff, decimals=4) %&gt;% \n  tab_header(\n    title = \"Country Equality, Full Selection\",\n    subtitle = \"Countries with better educated mothers have negative values, countries with better educated fathers have positive values.\"\n  ) %&gt;% \n  cols_label(\n    CNT = \"Country\",\n    mean_diff = \"Parental Education Difference\",\n    # add more columns as needed\n  )\n\n\n\n\n\n  \n    \n      Country Equality, Full Selection\n    \n    \n      Countries with better educated mothers have negative values, countries with better educated fathers have positive values.\n    \n    \n      Country\n      Parental Education Difference\n    \n  \n  \n    Türkiye\n−0.2320\n    Peru\n−0.2236\n    Morocco\n−0.2018\n    Kosovo\n−0.1834\n    Uzbekistan\n−0.1285\n    Saudi Arabia\n−0.1201\n    Cambodia\n−0.1157\n    Qatar\n−0.1101\n    Guatemala\n−0.0987\n    El Salvador\n−0.0957\n    Hong Kong (China)\n−0.0805\n    Bulgaria\n−0.0618\n    Viet Nam\n−0.0479\n    Baku (Azerbaijan)\n−0.0324\n    Kazakhstan\n−0.0226\n    Indonesia\n−0.0212\n    Korea\n−0.0174\n    Chinese Taipei\n−0.0114\n    Mexico\n0.0086\n    North Macedonia\n0.0107\n    Montenegro\n0.0122\n    Singapore\n0.0128\n    United Arab Emirates\n0.0139\n    Macao (China)\n0.0146\n    Paraguay\n0.0224\n    Switzerland\n0.0271\n    Canada\n0.0272\n    Romania\n0.0285\n    Austria\n0.0300\n    Brunei Darussalam\n0.0315\n    Georgia\n0.0357\n    Slovak Republic\n0.0385\n    Thailand\n0.0493\n    United States\n0.0500\n    Jordan\n0.0528\n    Japan\n0.0530\n    Germany\n0.0566\n    Philippines\n0.0621\n    Chile\n0.0625\n    Malaysia\n0.0728\n    Republic of Moldova\n0.0748\n    Serbia\n0.0804\n    Poland\n0.0827\n    Czech Republic\n0.0857\n    Palestinian Authority\n0.0860\n    Panama\n0.0933\n    Hungary\n0.0937\n    Greece\n0.0982\n    Netherlands\n0.0992\n    Croatia\n0.0994\n    France\n0.1038\n    Mongolia\n0.1090\n    Israel\n0.1162\n    Belgium\n0.1277\n    Slovenia\n0.1314\n    Estonia\n0.1335\n    Latvia\n0.1340\n    Jamaica\n0.1357\n    Colombia\n0.1419\n    Lithuania\n0.1462\n    Malta\n0.1534\n    Norway\n0.1597\n    Sweden\n0.1621\n    Australia\n0.1621\n    Italy\n0.1640\n    Finland\n0.1655\n    Denmark\n0.1672\n    United Kingdom\n0.1714\n    Brazil\n0.1748\n    Uruguay\n0.1760\n    Argentina\n0.1789\n    New Zealand\n0.1896\n    Ukrainian regions (18 of 27)\n0.1919\n    Spain\n0.2017\n    Iceland\n0.2200\n    Albania\n0.2287\n    Ireland\n0.2294\n    Dominican Republic\n0.2300\n    Portugal\n0.2312"
  },
  {
    "objectID": "posts/PISAtrends/PISAtrends.html",
    "href": "posts/PISAtrends/PISAtrends.html",
    "title": "Trends in PISA science scores",
    "section": "",
    "text": "library(arrow)\nlibrary(haven)\nlibrary(ggplot2) \nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2022/PISA_student_2022_subset.parquet\")\nPISA_2018 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2018/PISA_2018_student.parquet\")\nPISA_2015 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2015/PISA_2015_student.parquet\")\nPISA_2015&lt;-zap_labels(PISA_2015)\nPISA_2012 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2012/pisa_2012_student.parquet\")\nPISA_2012&lt;-zap_labels(PISA_2012)\nPISA_2009 &lt;- read_parquet(\"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/2009/pisa_2009_student.parquet\")\nPISA_2009&lt;-zap_labels(PISA_2009)\n\nI noticed from the PISA results that the Science scores appear to be decreasing.\n (OECD 2023b, 471)\nI wanted to know whether this trend was statistically significant. So I set about completing some unpaired t-tests and an anova test. This was using PISA data from 2009, 2015, 2018, and 2022.\nFirst, I checked that the data was normally distributed. For all four data sets this was shown to be true.\n\nUKSCI2022 &lt;-PISA_2022 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"United Kingdom\") \n\nggplot(data = UKSCI2022, \n       aes(x = PV1SCIE)) + \n  geom_histogram(binwidth = 5, fill = \"darkseagreen4\") +\n  ggtitle(\"2022\")\n\n\n\nUKSCI2018 &lt;-PISA_2018 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"United Kingdom\") \n\nggplot(data = UKSCI2018, \n       aes(x = PV1SCIE)) + \n  geom_histogram(binwidth = 5, fill = \"red\") +\n  ggtitle(\"2018\")\n\n\n\nUKSCI2015 &lt;-PISA_2015 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"GBR\") \n\nggplot(data = UKSCI2015, \n       aes(x = PV1SCIE)) + \n  geom_histogram(binwidth = 5, fill = \"orange\")  +\n  ggtitle(\"2015\")\n\n\n\nUKSCI2012 &lt;-PISA_2012 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"GBR\") \n\nggplot(data = UKSCI2012, \n       aes(x = PV1SCIE)) + \n  geom_histogram(binwidth = 5, fill = \"lightblue\")  +\n  ggtitle(\"2012\")\n\n\n\nUKSCI2009 &lt;-PISA_2009 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"GBR\") \n\nggplot(data = UKSCI2009, \n       aes(x = PV1SCIE)) + \n  geom_histogram(binwidth = 5, fill = \"purple\")  +\n  ggtitle(\"2009\")\n\n\n\nqqnorm(UKSCI2022$PV1SCIE) \nqqline(UKSCI2022$PV1SCIE, col = \"darkgreen\") \n\n\n\nqqnorm(UKSCI2018$PV1SCIE) \nqqline(UKSCI2018$PV1SCIE, col = \"red\") \n\n\n\nqqnorm(UKSCI2015$PV1SCIE) \nqqline(UKSCI2015$PV1SCIE, col = \"orange\") \n\n\n\nqqnorm(UKSCI2012$PV1SCIE) \nqqline(UKSCI2012$PV1SCIE, col = \"lightblue\") \n\n\n\nqqnorm(UKSCI2009$PV1SCIE) \nqqline(UKSCI2009$PV1SCIE, col = \"purple\") \n\n\n\n\nI then wanted to complete a t-test comparing the 2022 and 2018 data sets. So firstly checked the variances of the 2 data sets\n\nVarM &lt;- var(UKSCI2022$PV1SCIE, na.rm = TRUE) \n\nVarF &lt;- var(UKSCI2018$PV1SCIE, na.rm = TRUE) \n\nVarM / VarF \n\n[1] 1.162336\n\n\nThe variance ratio was close to 1 so the two conditions were met and so I could perform the t test.\nThe Null hypothesis would be that the mean of both 2018 and 2022 would be the same, with the alternative hypothesis being different.\n\nt.test(UKSCI2022$PV1SCIE, UKSCI2018$PV1SCIE,\n       paired = FALSE, alternative = \"two.sided\", var.equal = TRUE) \n\n\n    Two Sample t-test\n\ndata:  UKSCI2022$PV1SCIE and UKSCI2018$PV1SCIE\nt = -2.4775, df = 26788, p-value = 0.01324\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.3386075 -0.6225644\nsample estimates:\nmean of x mean of y \n 492.2651  495.2457 \n\n\nP value is 0.01324. This is lower than 0.025 so reject the null hypothesis. Accept the alternative hypothesis that the average PV1SCIE scores for 2018 and 2022 is statistically different.\nI went on to compare other years of data with the 2022 data. As can be seen by the p values shown in the results. The alternative hypothesis that the average PV1SCIE scores are statistically different. It is more convincing the further apart the years.\n\nt.test(UKSCI2022$PV1SCIE, UKSCI2018$PV1SCIE, paired = FALSE, alternative = \"two.sided\", var.equal = TRUE) \n\n\n    Two Sample t-test\n\ndata:  UKSCI2022$PV1SCIE and UKSCI2018$PV1SCIE\nt = -2.4775, df = 26788, p-value = 0.01324\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.3386075 -0.6225644\nsample estimates:\nmean of x mean of y \n 492.2651  495.2457 \n\nt.test(UKSCI2022$PV1SCIE, UKSCI2015$PV1SCIE,paired = FALSE, alternative = \"two.sided\", var.equal = TRUE) \n\n\n    Two Sample t-test\n\ndata:  UKSCI2022$PV1SCIE and UKSCI2015$PV1SCIE\nt = -9.3269, df = 27127, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -13.624038  -8.892244\nsample estimates:\nmean of x mean of y \n 492.2651  503.5233 \n\nt.test(UKSCI2022$PV1SCIE, UKSCI2009$PV1SCIE,paired = FALSE, alternative = \"two.sided\", var.equal = TRUE) \n\n\n    Two Sample t-test\n\ndata:  UKSCI2022$PV1SCIE and UKSCI2009$PV1SCIE\nt = -14.122, df = 25149, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -20.33945 -15.38160\nsample estimates:\nmean of x mean of y \n 492.2651  510.1256 \n\n\nSince I had 4 sets of PISA data, and there wanted to perform multiple t-tests for these difference dates. I then completed an anova test.\n\n\n\nUKSCI2009 &lt;-PISA_2009 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"GBR\")%&gt;% \n  mutate(year =\"2009\")   \n \nUKSCI2015 &lt;-PISA_2015 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"GBR\") %&gt;% \n  mutate(year =\"2015\") \n \nUKSCI2022 &lt;-PISA_2022 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"United Kingdom\")%&gt;% \n  mutate(year =\"2022\") \n \nUKSCI2018 &lt;-PISA_2018 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"United Kingdom\")%&gt;% \n  mutate(year =\"2018\") \n \nTotalPISA &lt;- rbind(UKSCI2022, UKSCI2018, UKSCI2015, UKSCI2009) \n \nresult &lt;- aov(data =TotalPISA, PV1SCIE ~ year) \nsumanova &lt;- summary(result) \nsumanova \n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nyear            3   2511892  837297    87.4 &lt;2e-16 ***\nResiduals   53122 508920819    9580                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe Pr(&gt;F) value is &lt;2e-16 which is over 0.05. This therefore suggests that the PV1Sci values are statistically different.\nMy question is: Why is it that there is a difference in the PV1SCIE scores. Why are they going down? What are the factors that could be causing this?\nTo further look at the results I ran a Tukey Test following on from the Anova. A Tukey Test can be used to determine which years have significant differences, in this case the mean PV1SCI scores in the UK.\n\nTukeyHSD(result) \n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ year, data = TotalPISA)\n\n$year\n                diff        lwr          upr     p adj\n2015-2009  -6.602382  -9.710095  -3.49466982 0.0000003\n2018-2009 -14.879938 -18.005230 -11.75464592 0.0000000\n2022-2009 -17.860524 -21.033200 -14.68784778 0.0000000\n2018-2015  -8.277555 -11.284561  -5.27054992 0.0000000\n2022-2015 -11.258141 -14.314365  -8.20191730 0.0000000\n2022-2018  -2.980586  -6.054684   0.09351177 0.0613144\n\n\nInterestingly, we cannot say there is a statistical difference between 2022 and 2018, since the p value is larger than 0.05. All other comparisons are statistically difference. Therefore I would agree with OECD (OECD 2023a) that the decline of Science values are not all down to the pandemic. There must be other factors for the decrease in science values. It would be interesting to investigate what is causing this pattern."
  },
  {
    "objectID": "posts/PISAtrends/PISAtrends.html#anova-test",
    "href": "posts/PISAtrends/PISAtrends.html#anova-test",
    "title": "Trends in PISA science scores",
    "section": "",
    "text": "UKSCI2009 &lt;-PISA_2009 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"GBR\")%&gt;% \n  mutate(year =\"2009\")   \n \nUKSCI2015 &lt;-PISA_2015 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"GBR\") %&gt;% \n  mutate(year =\"2015\") \n \nUKSCI2022 &lt;-PISA_2022 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"United Kingdom\")%&gt;% \n  mutate(year =\"2022\") \n \nUKSCI2018 &lt;-PISA_2018 %&gt;% \n  select(CNT, PV1SCIE) %&gt;% \n  filter(CNT == \"United Kingdom\")%&gt;% \n  mutate(year =\"2018\") \n \nTotalPISA &lt;- rbind(UKSCI2022, UKSCI2018, UKSCI2015, UKSCI2009) \n \nresult &lt;- aov(data =TotalPISA, PV1SCIE ~ year) \nsumanova &lt;- summary(result) \nsumanova \n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nyear            3   2511892  837297    87.4 &lt;2e-16 ***\nResiduals   53122 508920819    9580                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe Pr(&gt;F) value is &lt;2e-16 which is over 0.05. This therefore suggests that the PV1Sci values are statistically different.\nMy question is: Why is it that there is a difference in the PV1SCIE scores. Why are they going down? What are the factors that could be causing this?\nTo further look at the results I ran a Tukey Test following on from the Anova. A Tukey Test can be used to determine which years have significant differences, in this case the mean PV1SCI scores in the UK.\n\nTukeyHSD(result) \n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ year, data = TotalPISA)\n\n$year\n                diff        lwr          upr     p adj\n2015-2009  -6.602382  -9.710095  -3.49466982 0.0000003\n2018-2009 -14.879938 -18.005230 -11.75464592 0.0000000\n2022-2009 -17.860524 -21.033200 -14.68784778 0.0000000\n2018-2015  -8.277555 -11.284561  -5.27054992 0.0000000\n2022-2015 -11.258141 -14.314365  -8.20191730 0.0000000\n2022-2018  -2.980586  -6.054684   0.09351177 0.0613144\n\n\nInterestingly, we cannot say there is a statistical difference between 2022 and 2018, since the p value is larger than 0.05. All other comparisons are statistically difference. Therefore I would agree with OECD (OECD 2023a) that the decline of Science values are not all down to the pandemic. There must be other factors for the decrease in science values. It would be interesting to investigate what is causing this pattern."
  }
]